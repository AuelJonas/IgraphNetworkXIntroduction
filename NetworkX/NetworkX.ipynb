{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# creating Graphs using NetworkX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Undirected Graph:\n",
    "G = nx.Graph()\n",
    "# create nodes:\n",
    "List_of_nodes = [1, 2, 3, 5, \"Jonas\", \"Sven\"]\n",
    "G.add_nodes_from(List_of_nodes)\n",
    "nx.draw_networkx(G)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create edges:\n",
    "List_of_edges = [(1,2), (2,\"Jonas\"), (1,3), (3,5), (2,3), (\"Sven\",1), (\"Sven\",2), (\"Sven\",3), (\"Sven\",5)]\n",
    "G.add_edges_from(List_of_edges)\n",
    "nx.draw_networkx(G)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove nodes:\n",
    "G.remove_node(2)\n",
    "nx.draw_networkx(G)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create random graph:\n",
    "H = nx.Graph()\n",
    "# Graph can be created by only adding edges:\n",
    "for i in range(0, 10):\n",
    "    H.add_edge(random.randrange(0,10,1), random.randrange(0,10,1))\n",
    "nx.draw_networkx(H)\n",
    "plt.show()\n",
    "H.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directed Graph:\n",
    "I = nx.DiGraph()\n",
    "List_of_edges = [(\"Max\",\"Peter\"), (\"Peter\",\"Jonas\"), (\"Max\",\"Till\"), (\"Till\",\"Luisa\"), (\"Jonas\",\"Luisa\"), \n",
    "                 (\"Peter\",\"Till\"), (\"Sara\",\"Max\"), (\"Sara\",\"Peter\"), (\"Sara\",\"Till\"), (\"Sara\",\"Luisa\")]\n",
    "I.add_edges_from(List_of_edges)\n",
    "nx.draw_networkx(I)\n",
    "plt.show()\n",
    "plt.title(\"distribution of exercise solutions through students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multigraph:\n",
    "J = nx.MultiDiGraph()\n",
    "List_of_edges = [(\"Max\",\"Peter\"), (\"Peter\",\"Jonas\"), (\"Max\",\"Till\"), (\"Till\",\"Luisa\"), (\"Jonas\",\"Luisa\"), \n",
    "                 (\"Peter\",\"Till\"), (\"Sara\",\"Max\"), (\"Sara\",\"Peter\"), (\"Sara\",\"Till\"), (\"Sara\",\"Luisa\")]\n",
    "J.add_edges_from(List_of_edges)\n",
    "J.add_edge(\"Sara\",\"Peter\")\n",
    "nx.draw_networkx(J)\n",
    "plt.show()\n",
    "plt.title(\"distribution of exercise solutions through students\")\n",
    "J.edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyzing Networks using NetworkX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I = I.to_undirected()\n",
    "nx.draw_networkx(I)\n",
    "plt.show()\n",
    "plt.title(\"example social network\")\n",
    "# analyze graph I\n",
    "print(\"number of nodes in I: %d\" % I.number_of_nodes())\n",
    "print(\"number of edges in I: %d\" % I.number_of_edges())\n",
    "print(\"Sara is friends with:\") \n",
    "print(I.neighbors(\"Sara\"))\n",
    "print(\"degree of nodes in I:\")\n",
    "I.degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# analyze graph H\n",
    "print(nx.is_connected(H))\n",
    "print(nx.is_directed(H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network algorithm on example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = nx.betweenness_centrality(I, k = None, normalized = True, endpoints = False, seed = None)\n",
    "#d = nx.degree_centrality(I)\n",
    "#c = nx.closeness_centrality(I)\n",
    "d = {\"Betweenness\": b}#, \"Degree centrality\": d, \"Closeness centrality\": c}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def betweenness_centrality(G, k=None, normalized=True, weight=None, endpoints=False, seed=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : graph\n",
    "      A NetworkX graph\n",
    "\n",
    "    k : int, optional (default=None)\n",
    "      If k is not None use k node samples to estimate betweenness.\n",
    "      The value of k <= n where n is the number of nodes in the graph.\n",
    "      Higher values give better approximation.\n",
    "\n",
    "    normalized : bool, optional\n",
    "      If True the betweenness values are normalized by `2/((n-1)(n-2))`\n",
    "      for graphs, and `1/((n-1)(n-2))` for directed graphs where `n`\n",
    "      is the number of nodes in G.\n",
    "\n",
    "    weight : None or string, optional\n",
    "      If None, all edge weights are considered equal.\n",
    "      Otherwise holds the name of the edge attribute used as weight.\n",
    "\n",
    "    endpoints : bool, optional\n",
    "      If True include the endpoints in the shortest path counts.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : dictionary\n",
    "       Dictionary of nodes with betweenness centrality as the value.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The algorithm is from Ulrik Brandes [1]_.\n",
    "    See [4]_ for the original first published version and [2]_ for details on\n",
    "    algorithms for variations and related metrics.\n",
    "\n",
    "    For approximate betweenness calculations set k=#samples to use\n",
    "    k nodes (\"pivots\") to estimate the betweenness values. For an estimate\n",
    "    of the number of pivots needed see [3]_.\n",
    "\n",
    "    For weighted graphs the edge weights must be greater than zero.\n",
    "    Zero edge weights can produce an infinite number of equal length\n",
    "    paths between pairs of nodes.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Ulrik Brandes:\n",
    "       A Faster Algorithm for Betweenness Centrality.\n",
    "       Journal of Mathematical Sociology 25(2):163-177, 2001.\n",
    "       http://www.inf.uni-konstanz.de/algo/publications/b-fabc-01.pdf\n",
    "    .. [2] Ulrik Brandes:\n",
    "       On Variants of Shortest-Path Betweenness\n",
    "       Centrality and their Generic Computation.\n",
    "       Social Networks 30(2):136-145, 2008.\n",
    "       http://www.inf.uni-konstanz.de/algo/publications/b-vspbc-08.pdf\n",
    "    .. [3] Ulrik Brandes and Christian Pich:\n",
    "       Centrality Estimation in Large Networks.\n",
    "       International Journal of Bifurcation and Chaos 17(7):2303-2318, 2007.\n",
    "       http://www.inf.uni-konstanz.de/algo/publications/bp-celn-06.pdf\n",
    "    .. [4] Linton C. Freeman:\n",
    "       A set of measures of centrality based on betweenness.\n",
    "       Sociometry 40: 35â€“41, 1977\n",
    "       http://moreno.ss.uci.edu/23.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    betweenness = dict.fromkeys(G, 0.0)  # b[v]=0 for v in G\n",
    "    if k is None:\n",
    "        nodes = G\n",
    "    else:\n",
    "        random.seed(seed)\n",
    "        nodes = random.sample(G.nodes(), k)\n",
    "    for s in nodes:\n",
    "        # single source shortest paths\n",
    "        if weight is None:  # use BFS\n",
    "            S, P, sigma = _single_source_shortest_path_basic(G, s)\n",
    "        else:  # use Dijkstra's algorithm\n",
    "            S, P, sigma = _single_source_dijkstra_path_basic(G, s, weight)\n",
    "        # accumulation\n",
    "        if endpoints:\n",
    "            betweenness = _accumulate_endpoints(betweenness, S, P, sigma, s)\n",
    "        else:\n",
    "            betweenness = _accumulate_basic(betweenness, S, P, sigma, s)\n",
    "    # rescaling\n",
    "    betweenness = _rescale(betweenness, len(G),\n",
    "                           normalized=normalized,\n",
    "                           directed=G.is_directed(),\n",
    "                           k=k)\n",
    "    return betweenness\n",
    "\n",
    "# helpers for betweenness centrality\n",
    "\n",
    "def _single_source_shortest_path_basic(G, s):\n",
    "    S = []\n",
    "    P = {}\n",
    "    for v in G:\n",
    "        P[v] = []\n",
    "    sigma = dict.fromkeys(G, 0.0)    # sigma[v]=0 for v in G\n",
    "    D = {}\n",
    "    sigma[s] = 1.0\n",
    "    D[s] = 0\n",
    "    Q = [s]\n",
    "    while Q:   # use BFS to find shortest paths\n",
    "        v = Q.pop(0)\n",
    "        S.append(v)\n",
    "        Dv = D[v]\n",
    "        sigmav = sigma[v]\n",
    "        for w in G[v]:\n",
    "            if w not in D:\n",
    "                Q.append(w)\n",
    "                D[w] = Dv + 1\n",
    "            if D[w] == Dv + 1:   # this is a shortest path, count paths\n",
    "                sigma[w] += sigmav\n",
    "                P[w].append(v)  # predecessors\n",
    "    return S, P, sigma\n",
    "\n",
    "\n",
    "def _single_source_dijkstra_path_basic(G, s, weight='weight'):\n",
    "    # modified from Eppstein\n",
    "    S = []\n",
    "    P = {}\n",
    "    for v in G:\n",
    "        P[v] = []\n",
    "    sigma = dict.fromkeys(G, 0.0)    # sigma[v]=0 for v in G\n",
    "    D = {}\n",
    "    sigma[s] = 1.0\n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "    seen = {s: 0}\n",
    "    c = count()\n",
    "    Q = []   # use Q as heap with (distance,node id) tuples\n",
    "    push(Q, (0, next(c), s, s))\n",
    "    while Q:\n",
    "        (dist, _, pred, v) = pop(Q)\n",
    "        if v in D:\n",
    "            continue  # already searched this node.\n",
    "        sigma[v] += sigma[pred]  # count paths\n",
    "        S.append(v)\n",
    "        D[v] = dist\n",
    "        for w, edgedata in G[v].items():\n",
    "            vw_dist = dist + edgedata.get(weight, 1)\n",
    "            if w not in D and (w not in seen or vw_dist < seen[w]):\n",
    "                seen[w] = vw_dist\n",
    "                push(Q, (vw_dist, next(c), v, w))\n",
    "                sigma[w] = 0.0\n",
    "                P[w] = [v]\n",
    "            elif vw_dist == seen[w]:  # handle equal paths\n",
    "                sigma[w] += sigma[v]\n",
    "                P[w].append(v)\n",
    "    return S, P, sigma\n",
    "\n",
    "\n",
    "def _accumulate_basic(betweenness, S, P, sigma, s):\n",
    "    delta = dict.fromkeys(S, 0)\n",
    "    while S:\n",
    "        w = S.pop()\n",
    "        coeff = (1.0 + delta[w]) / sigma[w]\n",
    "        for v in P[w]:\n",
    "            delta[v] += sigma[v] * coeff\n",
    "        if w != s:\n",
    "            betweenness[w] += delta[w]\n",
    "    return betweenness\n",
    "\n",
    "\n",
    "def _accumulate_endpoints(betweenness, S, P, sigma, s):\n",
    "    betweenness[s] += len(S) - 1\n",
    "    delta = dict.fromkeys(S, 0)\n",
    "    while S:\n",
    "        w = S.pop()\n",
    "        coeff = (1.0 + delta[w]) / sigma[w]\n",
    "        for v in P[w]:\n",
    "            delta[v] += sigma[v] * coeff\n",
    "        if w != s:\n",
    "            betweenness[w] += delta[w] + 1\n",
    "    return betweenness\n",
    "\n",
    "\n",
    "def _rescale(betweenness, n, normalized, directed=False, k=None):\n",
    "    if normalized is True:\n",
    "        if n <= 2:\n",
    "            scale = None  # no normalization b=0 for all nodes\n",
    "        else:\n",
    "            scale = 1.0 / ((n - 1) * (n - 2))\n",
    "    else:  # rescale by 2 for undirected graphs\n",
    "        if not directed:\n",
    "            scale = 1.0 / 2.0\n",
    "        else:\n",
    "            scale = None\n",
    "    if scale is not None:\n",
    "        if k is not None:\n",
    "            scale = scale * n / k\n",
    "        for v in betweenness:\n",
    "            betweenness[v] *= scale\n",
    "    return betweenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Centrality measures of Krackhardt social network.\n",
    "\"\"\"\n",
    "# Author: Aric Hagberg (hagberg@lanl.gov)\n",
    "# Date: 2005-05-12 14:33:11 -0600 (Thu, 12 May 2005)\n",
    "# Revision: 998\n",
    "\n",
    "#    Copyright (C) 2004-2016 by\n",
    "#    Aric Hagberg <hagberg@lanl.gov>\n",
    "#    Dan Schult <dschult@colgate.edu>\n",
    "#    Pieter Swart <swart@lanl.gov>\n",
    "#    All rights reserved.\n",
    "#    BSD license.\n",
    "\n",
    "J = krackhardt_kite_graph()\n",
    "nx.draw_networkx(J, with_labels = True)\n",
    "plt.title('Krackhardt Graph')\n",
    "plt.show()\n",
    "b = nx.betweenness_centrality(J)\n",
    "d = nx.degree_centrality(J)\n",
    "c = nx.closeness_centrality(J)\n",
    "d = {\"Betweenness\": b, \"Degree centrality\": d, \"Closeness centrality\": c}\n",
    "pd.DataFrame(d)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
